{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0989a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "#from langchain_community.llms import Ollama\n",
    "#from langchain_community.chat_models import ChatOllama\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "#from langchain_ollama import OllamaEmbeddings\n",
    "import os\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from typing import Literal\n",
    "#from langgraph.graph import END\n",
    "from langgraph.graph import START, END\n",
    "from langgraph.graph import MessagesState, StateGraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b17b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\worb1\\AppData\\Local\\Temp\\ipykernel_20164\\122708114.py:3: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embeddings = OllamaEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "# model cell\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"bge-m3\"\n",
    ")\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"qwen3:4b\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e7c14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chroma DB에 41개의 문서를 임베딩하여 저장 완료.\n"
     ]
    }
   ],
   "source": [
    "# 1. 문서 로드\n",
    "loader = TextLoader(\"./docs/RFP_requirements.md\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "# 2. 문서 나누기\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "splits = text_splitter.split_documents(documents)\n",
    "\n",
    "# 3. 벡터 스토어 생성\n",
    "persist_directory = \"./chroma_db\"\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings, persist_directory=persist_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1332a218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 검색 결과: [Document(id='5512e0cb-b514-4c1c-b7c4-b91cc93bb21d', metadata={'source': './docs/RFP_requirements.md'}, page_content='- **요구사항ID**: SFR-014\\n- **유형**: 기능 요구사항\\n- **대분류**: 구축 LMS (Learning Management System)\\n- **중분류**: 대한체육회 체육인재개발원 포털 구축\\n- **소분류**:\\n  - **기본정보 조회**\\n    - 인사말, 연혁, 교육비전, 교육일정, 부서안내, 찾아오시는 길 등 정보 조회 :contentReference[oaicite:0]{index=0}&#8203;:contentReference[oaicite:1]{index=1}\\n  - **교육안내**\\n    - 교육신청절차, 수료기준, 준수사항, 연간교육계획, 교육훈련근거 등 정보 조회 :contentReference[oaicite:2]{index=2}&#8203;:contentReference[oaicite:3]{index=3}\\n  - **교육신청**\\n    - 과정별 안내 및 교육 검색 기능 제공\\n    - 집합교육·온라인교육 구분 조회 및 신청 기능 제공\\n    - 대상(선수·지도자·심판·행정가·일반체육인)별 정보 제공\\n    - 분야별(스포츠·어학·소양·자격) 교육 정보 제공\\n    - 심판·지도자 강습회 정보 제공 :contentReference[oaicite:4]{index=4}&#8203;:contentReference[oaicite:5]{index=5}\\n  - **학습자 마이페이지 기능**\\n    - 출결조회·진도율 등 진행 중 교육 과정 현황 조회\\n    - 교육이력·경기인 등록 이력 등 이력 정보 제공\\n    - 이수증 발급·교재 다운로드 등 편의 기능 제공\\n    - 만족도 평가 기능 및 Q&A 제공\\n    - 관심분야 등록·수정 및 맞춤형 교육 추천 기능\\n    - 수료증 발급 기능 제공 :contentReference[oaicite:6]{index=6}&#8203;:contentReference[oaicite:7]{index=7}\\n  - **게시판·고객지원**\\n    - 공지사항·새 소식·자료실 게시판'), Document(id='76ab3505-0a7d-4b75-adbd-e15b4932c336', metadata={'source': './docs/RFP_requirements.md'}, page_content='- **요구사항명**: 연계 구축 API\\n- **설명**:  \\n  스포츠지원포털, 체육정보시스템, 증명서발급 관리 시스템, 학습관리시스템 간에 실시간 양방향 데이터 연계를 위한 API 환경을 구축해야 한다. 이를 통해 교육과정 조회, 수료내역 관리, 증명서 발급 신청·승인·발급 이력 조회 등의 모든 주요 연계 프로세스를 자동화하고 통합 관리할 수 있어야 한다.\\n\\n- **근거문서**:\\n  - RFP III‑3 “상세 요구사항” SFR‑015 :contentReference[oaicite:1]{index=1}\\n\\n- **비고**:\\n  - 산출물: 요구사항정의서, 요구사항추적표, 인터페이스정의서, 화면설계서  \\n\\n## PER-001: 동시 사용자 접속 수\\n\\n- **정의**: 시스템 당 동시 접속 성능\\n- **세부내용**: 시스템 당 동시 사용자 500명 이상 지원해야 하고, 이때 성능이 저하되지 않아야 한다. ‘지난 5분 이상 요청한 사람들’을 로그인 사용자로 간주한다. :contentReference[oaicite:0]{index=0}&#8203;:contentReference[oaicite:1]{index=1}\\n- **산출정보**: 성능시험결과서\\n\\n## PER-002: 웹 페이지 응답 시간\\n\\n- **정의**: 웹페이지 응답 요구 시간\\n- **세부내용**:\\n  - 모든 질의는 사용자가 요청한 시점부터 3,000ms(3초) 이내에 결과를 보여줘야 한다.\\n  - 각 웹페이지는 로컬 10Mbps 네트워크 환경에서 사용자 요청 후 3,000ms 이내에 화면에 표시되어야 한다.\\n  - 이 요구사항은 하나 이상의 큰 이미지(50KB 이상) 또는 동영상을 포함하는 페이지에는 적용되지 않는다.\\n  - 동시 사용자 수가 용량의 90%를 초과한 경우에도 이 조건은 제외된다. :contentReference[oaicite:2]{index=2}\\n- **산출정보**: 성능시험결과서\\n\\n## PER-003: 오류 응답 처리'), Document(id='ea800e8b-0ad7-4f54-964d-5ae4a69d9c29', metadata={'source': './docs/RFP_requirements.md'}, page_content='- **요구사항ID**: SIR-009\\n- **유형**: 인터페이스 요구사항\\n- **정의**: 스포츠지원포털 통합회원 적용 및 적용 SSO (Single Sign On)\\n\\n- **세부내용**:\\n  - 스포츠지원포털 회원정보 기반 SSO 기능 구현\\n  - 학습관리시스템 회원가입 시 스포츠지원포털로 이동하여 가입 처리\\n  - 학습관리시스템 로그인 시 SSO를 통해 스포츠지원포털 로그인 화면으로 리디렉션\\n  - 포털 로그인 완료 후 학습관리시스템으로 자동 복귀하여 서비스 이용\\n\\n- **산출정보**: 내부 시스템 간 연계 정의서  \\n\\n## SIR-010: 교육과정정보 연계\\n\\n- **요구사항ID**: SIR-010\\n- **유형**: 인터페이스 요구사항\\n- **정의**: 학습관리시스템에 등록된 교육과정 정보를 스포츠지원포털에서 실시간 조회할 수 있도록 데이터 연계 및 구현\\n\\n- **세부내용**:\\n  - **연계방식**: API\\n  - **연계대상**:\\n    - 학습관리시스템에 등록된 교육과정 정보\\n    - 관련 코드정보 및 교육과정 메타데이터\\n  - **연계주기**: 실시간\\n  - **연계정보**:\\n    - 교육 카테고리, 교육명, 교육기간, 교육방식\\n    - 회차정보, 교육대상, 교육수료여부\\n  - **구현요건**:\\n    - 스포츠지원포털의 교육정보 화면에서 학습관리시스템 데이터를 실시간으로 조회·표시\\n\\n- **산출정보**: 내부 시스템 간 연계 정의서  \\n\\n## SIR-011: 교육수료정보 연계\\n\\n- **요구사항ID**: SIR-011\\n- **유형**: 인터페이스 요구사항\\n- **정의**: 교육수료정보 연계')]\n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "query = \"로그인 기능에 필요한 요소는 무엇인가요?\"\n",
    "\n",
    "result = retriever.invoke(query)\n",
    "\n",
    "print(f\"✅ 검색 결과: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe41c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists('./fastmcp-server/requirments_collection') and len(os.listdir('./fastmcp-server/requirments_collection')) > 0:\n",
    "    vector_store = Chroma(\n",
    "        embedding_function=embeddings,\n",
    "        collection_name = 'requirments_collection',\n",
    "        persist_directory = './requirments_collection'\n",
    "    )\n",
    "else:\n",
    "    print(\"⚙️ Chroma DB not found. Creating new DB...\")\n",
    "\n",
    "    # ① 문서 로드\n",
    "    loader = TextLoader(\"docs.txt\", encoding=\"utf-8\")\n",
    "    documents = loader.load()\n",
    "\n",
    "    # ② 텍스트 분할\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50,\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "    # ③ Chroma DB 생성 및 persist\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        split_docs,\n",
    "        embedding=embeddings,\n",
    "        persist_directory='./requirments_collection'\n",
    "    )\n",
    "    print(\"✅ Chroma DB created and persisted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7ba886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "#from utils.config import get_llm\n",
    "from workflow.state import AgentState\n",
    "from langchain import hub\n",
    "from typing import Literal\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.types import Command\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "AOAI_DEPLOY_EMBED_3_LARGE=os.getenv(\"AOAI_DEPLOY_EMBED_3_LARGE\")\n",
    "AOAI_API_KEY=os.getenv(\"AOAI_API_KEY\")\n",
    "AOAI_ENDPOINT=os.getenv(\"AOAI_ENDPOINT\")\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    model=AOAI_DEPLOY_EMBED_3_LARGE,\n",
    "    openai_api_version=\"2024-02-01\",\n",
    "    api_key= AOAI_API_KEY,\n",
    "    azure_endpoint=AOAI_ENDPOINT\n",
    "    )\n",
    "\n",
    "if os.path.exists('./income_tax_collection') and len(os.listdir('./income_tax_collection')) > 0:\n",
    "    vector_store = Chroma(\n",
    "        embedding_function=embeddings,\n",
    "        collection_name = 'income_tax_collection',\n",
    "        persist_directory = './income_tax_collection'\n",
    "    )\n",
    "else:\n",
    "    print(\"⚙️ Chroma DB not found. Creating new DB...\")\n",
    "\n",
    "    # ① 문서 로드\n",
    "    loader = TextLoader(\"example.txt\", encoding=\"utf-8\")\n",
    "    documents = loader.load()\n",
    "\n",
    "    # ② 텍스트 분할\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50,\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "    # ③ Chroma DB 생성 및 persist\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        split_docs,\n",
    "        embedding=embeddings,\n",
    "        persist_directory='./income_tax_collection'\n",
    "    )\n",
    "    print(\"✅ Chroma DB created and persisted.\")\n",
    "\n",
    "retriever = vector_store.as_retriever(search_kwargs={'k': 3})\n",
    "\n",
    "# RAG 프롬프트를 가져옵니다.\n",
    "generate_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# LangChain Azure OpenAI 설정\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_key=os.getenv(\"AOAI_API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AOAI_ENDPOINT\"),\n",
    "    azure_deployment=os.getenv(\"AOAI_DEPLOY_GPT4O\"),\n",
    "    api_version=os.getenv(\"AOAI_API_VERSION\"),\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def retrieve(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    사용자의 질문에 기반하여 벡터 스토어에서 관련 문서를 검색합니다.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): 사용자의 질문을 포함한 에이전트의 현재 state.\n",
    "\n",
    "    Returns:\n",
    "        AgentState: 검색된 문서가 추가된 state를 반환합니다.\n",
    "    \"\"\"\n",
    "    query = state.query  # state에서 사용자의 질문을 추출합니다.\n",
    "    docs = retriever.invoke(query)  # 질문과 관련된 문서를 검색합니다.\n",
    "    #return {'context': docs}  # 검색된 문서를 포함한 state를 반환합니다.\n",
    "\n",
    "    return AgentState(\n",
    "            query=state.query,\n",
    "            context=docs,\n",
    "            rewrite_count=state.rewrite_count\n",
    "        )\n",
    "\n",
    "def generate(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    주어진 state를 기반으로 RAG 체인을 사용하여 응답을 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): 사용자의 질문과 문맥을 포함한 에이전트의 현재 state.\n",
    "\n",
    "    Returns:\n",
    "        AgentState: 생성된 응답을 포함하는 state를 반환합니다.\n",
    "    \"\"\"\n",
    "    context = state.context  # state에서 문맥을 추출합니다.\n",
    "    query = state.query      # state에서 사용자의 질문을 추출합니다.\n",
    "    \n",
    "    # RAG 체인을 구성합니다.\n",
    "    rag_chain = generate_prompt | llm\n",
    "    \n",
    "    # 질문과 문맥을 사용하여 응답을 생성합니다.\n",
    "    response = rag_chain.invoke({'question': query, 'context': context})\n",
    "    \n",
    "    #return {'answer': response}  # 생성된 응답을 포함하는 state를 반환합니다.\n",
    "\n",
    "    return AgentState(\n",
    "        query=state.query,\n",
    "        context=state.context,\n",
    "        answer=response.content,\n",
    "        rewrite_count=state.rewrite_count\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# 문서 관련성 판단을 위한 프롬프트를 가져옵니다.\n",
    "doc_relevance_prompt = hub.pull(\"langchain-ai/rag-document-relevance\")\n",
    "\n",
    "def check_doc_relevance(state: AgentState) -> Literal['generate', 'rewrite']:\n",
    "    \"\"\"\n",
    "    주어진 state를 기반으로 문서의 관련성을 판단합니다.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): 사용자의 질문과 문맥을 포함한 에이전트의 현재 state.\n",
    "\n",
    "    Returns:\n",
    "        Literal['generate', 'rewrite']: 문서가 관련성이 높으면 'generate', 그렇지 않으면 'rewrite'를 반환합니다.\n",
    "    \"\"\"\n",
    "    query = state.query  # state에서 사용자의 질문을 추출합니다.\n",
    "    context = state.context  # state에서 문맥을 추출합니다.\n",
    "\n",
    "    # 문서 관련성 판단 체인을 구성합니다.\n",
    "    doc_relevance_chain = doc_relevance_prompt | llm\n",
    "    \n",
    "    # 질문과 문맥을 사용하여 문서의 관련성을 판단합니다.\n",
    "    response = doc_relevance_chain.invoke({'question': query, 'documents': context})\n",
    "\n",
    "    if state.rewrite_count >= 3:\n",
    "        return \"generate\"\n",
    "        \n",
    "    # 관련성이 높으면 'generate'를 반환하고, 그렇지 않으면 'rewrite'를 반환합니다.\n",
    "    if response['Score'] == 1:\n",
    "        return 'generate'\n",
    "    else:\n",
    "        state.rewrite_count += 1\n",
    "        return 'rewrite'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 사전 정의: 특정 표현을 다른 표현으로 변환하기 위한 사전입니다.\n",
    "dictionary = ['사람과 관련된 표현 -> 거주자']\n",
    "\n",
    "# 프롬프트 템플릿을 생성합니다. 사용자의 질문을 사전을 참고하여 변경합니다.\n",
    "rewrite_prompt = PromptTemplate.from_template(f\"\"\"\n",
    "사용자의 질문을 보고, 우리의 사전을 참고해서 사용자의 질문을 변경해주세요 \n",
    "사전: {dictionary}                                           \n",
    "질문: {{query}}\n",
    "\"\"\")\n",
    "\n",
    "def rewrite(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    사용자의 질문을 사전을 참고하여 변경합니다.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): 사용자의 질문을 포함한 에이전트의 현재 state.\n",
    "\n",
    "    Returns:\n",
    "        AgentState: 변경된 질문을 포함하는 state를 반환합니다.\n",
    "    \"\"\"\n",
    "    query = state.query  # state에서 사용자의 질문을 추출합니다.\n",
    "    \n",
    "    # 리라이트 체인을 구성합니다. 프롬프트, LLM, 출력 파서를 연결합니다.\n",
    "    rewrite_chain = rewrite_prompt | llm | StrOutputParser()\n",
    "\n",
    "    # 질문을 변경합니다.\n",
    "    response = rewrite_chain.invoke({'query': query})\n",
    "    \n",
    "    #return {'query': response}  # 변경된 질문을 포함하는 state를 반환합니다.\n",
    "\n",
    "    return AgentState(\n",
    "        query=response,\n",
    "        context=state.context,\n",
    "        answer=state.answer,\n",
    "        rewrite_count=state.rewrite_count\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    DuckDuckGo를 이용한 간단한 웹 검색.\n",
    "    \"\"\"\n",
    "    url = f\"https://html.duckduckgo.com/html/?q={query}\"\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=5)\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        results = soup.find_all(\"a\", class_=\"result__a\")\n",
    "        snippets = [a.text for a in results[:3]]\n",
    "        return \"\\n\".join(snippets) if snippets else \"검색 결과가 없습니다.\"\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"검색 중 오류가 발생했습니다.\"\n",
    "\n",
    "# 추가 한거\n",
    "web_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=[web_search],\n",
    "    prompt=\"당신은 최신 정보를 찾기 위해 웹 검색을 수행하는 웹봇입니다. 사용자 질문을 검색해서 답변하세요.\"\n",
    ")\n",
    "\n",
    "def web_node(state: AgentState) -> AgentState:\n",
    "    # DuckDuckGo tool 호출\n",
    "    search_result = web_search(state.query)\n",
    "\n",
    "    web_prompt = f\"\"\"\n",
    "    당신은 최신 정보를 찾기 위해 웹 검색을 수행하는 웹봇입니다.\n",
    "    아래 검색 결과를 참고하여 사용자 질문에 답변하세요.\n",
    "\n",
    "    검색결과:\n",
    "    {search_result}\n",
    "\n",
    "    질문: {state.query}\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke([HumanMessage(content=web_prompt)])\n",
    "    text = getattr(response, \"content\", str(response))\n",
    "\n",
    "    return AgentState(\n",
    "        query=state.query,\n",
    "        context=state.context,\n",
    "        answer=text,\n",
    "        rewrite_count=state.rewrite_count\n",
    "    )\n",
    "\n",
    "\n",
    "#def web_node(state: AgentState) -> AgentState:\n",
    "#    result = web_agent.invoke(state)\n",
    "#    return Command(\n",
    "#        update={\n",
    "#            \"messages\": [\n",
    "#                HumanMessage(\n",
    "#                    content=result[\"messages\"][-1].content,\n",
    "#                    name=\"web_search\"\n",
    "#                )\n",
    "#            ]\n",
    "#        },\n",
    "#        goto=\"supervisor\",\n",
    "#    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
